{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. \n",
    "Random Forest Regressor is an ensemble learning algorithm used for regression tasks.\n",
    "It builds multiple decision trees during training and outputs the average prediction (for regression) of the individual trees.\n",
    "\n",
    "2.\n",
    "Random Forest Regressor reduces overfitting by training each tree on a random subset of the data (bootstrap samples) and considering only a random subset of features at each split.\n",
    "By introducing randomness, it decorrelates the individual trees, making the ensemble more robust and less prone to overfitting the training data.\n",
    "\n",
    "3. \n",
    "Each tree in the Random Forest independently makes predictions.\n",
    "For regression tasks, the final prediction is often the average of the predictions of all the individual trees. This averaging helps smooth out individual tree predictions and provides a more stable and accurate overall prediction.\n",
    "\n",
    "4. \n",
    "Some key hyperparameters of Random Forest Regressor include:\n",
    "n_estimators: Number of trees in the forest.\n",
    "max_depth: Maximum depth of the individual trees.\n",
    "min_samples_split: Minimum number of samples required to split an internal node.\n",
    "min_samples_leaf: Minimum number of samples required to be at a leaf node.\n",
    "max_features: Number of features to consider for the best split.\n",
    "\n",
    "5. \n",
    "Random Forest is an ensemble of decision trees, whereas Decision Tree Regressor consists of a single decision tree.\n",
    "Random Forest introduces randomness in both the data sampling and feature selection, reducing overfitting.\n",
    "Decision Tree is more prone to overfitting as it can capture noise in the training data.\n",
    "\n",
    "6. \n",
    "Advantages:\n",
    "Robust to overfitting due to ensemble nature.\n",
    "Handles both numerical and categorical data.\n",
    "Provides feature importances.\n",
    "Disadvantages:\n",
    "Less interpretable compared to a single decision tree.\n",
    "May require more computational resources due to multiple trees.\n",
    "\n",
    "7. \n",
    "For regression tasks, the output of Random Forest Regressor is a continuous numerical value, representing the predicted target variable.\n",
    "\n",
    "8. \n",
    "While Random Forest is primarily designed for regression, there is a counterpart called Random Forest Classifier specifically designed for classification tasks.\n",
    "Random Forest Classifier predicts the class labels instead of continuous values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
